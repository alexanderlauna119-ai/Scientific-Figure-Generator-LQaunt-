# -*- coding: utf-8 -*-
"""survival_tool.py

A lightweight Kaplan–Meier (KM) plotting + basic survival analysis GUI.

- No external survival libraries required.
- Supports:
  * KM curves (1+ groups)
  * Median survival per group
  * Log-rank test (2+ groups)
  * Optional Greenwood CI (log-log)

Designed to be imported and launched from an existing Tkinter app toolbar.

Author: generated by M365 Copilot
"""

from __future__ import annotations

import os
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import tkinter as tk
from tkinter import ttk, filedialog, messagebox


# -----------------------------
# Core survival math
# -----------------------------

def _clean_event_vector(event: pd.Series) -> np.ndarray:
    """Map event/censor values to {0,1}.

    Accepts 0/1, False/True, 'censored'/'event', etc.
    Non-zero numeric -> 1.
    """
    if event.dtype == bool:
        return event.astype(int).to_numpy()

    # Try numeric first
    ev_num = pd.to_numeric(event, errors='coerce')
    if ev_num.notna().any():
        return (ev_num.fillna(0).astype(float) != 0).astype(int).to_numpy()

    # Fall back to string mapping
    ev_str = event.astype(str).str.strip().str.lower()
    one = {"1", "true", "t", "yes", "y", "event", "dead", "death", "progressed", "progression"}
    zero = {"0", "false", "f", "no", "n", "censored", "censor", "alive", "none"}
    out = np.zeros(len(ev_str), dtype=int)
    out[ev_str.isin(one)] = 1
    out[ev_str.isin(zero)] = 0
    # Unknown strings -> 0
    return out


@dataclass
class KMResult:
    time: np.ndarray          # event times grid (including 0)
    survival: np.ndarray      # S(t)
    n_at_risk: np.ndarray     # n(t) at each event time (same length as time)
    n_events: np.ndarray      # d(t) at each event time
    var_greenwood: np.ndarray # Greenwood variance of S(t)


def kaplan_meier(time: np.ndarray, event: np.ndarray) -> KMResult:
    """Compute Kaplan–Meier estimate.

    Parameters
    ----------
    time : array-like
        Follow-up time.
    event : array-like
        1=event observed, 0=censored.

    Returns
    -------
    KMResult
    """
    t = np.asarray(time, dtype=float)
    e = np.asarray(event, dtype=int)

    mask = np.isfinite(t) & np.isfinite(e)
    t = t[mask]
    e = e[mask]

    if t.size == 0:
        raise ValueError("No valid (time, event) rows after cleaning.")

    # sort by time
    order = np.argsort(t)
    t = t[order]
    e = e[order]

    # unique event times (only where event==1)
    event_times = np.unique(t[e == 1])

    # include t=0 as baseline
    times = np.concatenate(([0.0], event_times))

    surv = np.ones(times.shape[0], dtype=float)
    n_risk = np.zeros_like(surv)
    d_evt = np.zeros_like(surv)

    # Greenwood cumulative sum term: sum(d/(n(n-d)))
    green_cum = np.zeros_like(surv)

    for i, ti in enumerate(times):
        if i == 0:
            n = (t >= 0).sum()
            n_risk[i] = n
            d_evt[i] = 0
            surv[i] = 1.0
            green_cum[i] = 0.0
            continue

        n = (t >= ti).sum()
        d = ((t == ti) & (e == 1)).sum()

        n_risk[i] = n
        d_evt[i] = d

        if n <= 0:
            surv[i] = surv[i - 1]
            green_cum[i] = green_cum[i - 1]
            continue

        if d == 0:
            surv[i] = surv[i - 1]
            green_cum[i] = green_cum[i - 1]
        else:
            surv[i] = surv[i - 1] * (1.0 - d / n)
            # Greenwood increment
            if n - d > 0:
                green_cum[i] = green_cum[i - 1] + (d / (n * (n - d)))
            else:
                green_cum[i] = green_cum[i - 1]

    var = (surv ** 2) * green_cum
    return KMResult(time=times, survival=surv, n_at_risk=n_risk, n_events=d_evt, var_greenwood=var)


def km_loglog_ci(km: KMResult, alpha: float = 0.05) -> Tuple[np.ndarray, np.ndarray]:
    """Approximate (1-alpha) CI using log-log transform and Greenwood.

    Returns arrays (lower, upper) aligned with km.time.
    """
    z = float(abs(_norm_ppf(1 - alpha / 2)))
    S = np.clip(km.survival, 1e-12, 1.0)
    varS = np.clip(km.var_greenwood, 0.0, np.inf)

    # se of log(-log(S))
    with np.errstate(divide='ignore', invalid='ignore'):
        se = np.sqrt(varS) / (S * np.abs(np.log(S)))
        y = np.log(-np.log(S))

    lower = np.exp(-np.exp(y + z * se))
    upper = np.exp(-np.exp(y - z * se))

    # baseline point
    lower[0] = 1.0
    upper[0] = 1.0

    lower = np.clip(lower, 0.0, 1.0)
    upper = np.clip(upper, 0.0, 1.0)
    return lower, upper


def _norm_ppf(p: float) -> float:
    """Inverse CDF for standard normal.

    Uses a rational approximation (Acklam) to avoid SciPy dependency.
    """
    # Guard
    if p <= 0.0:
        return -np.inf
    if p >= 1.0:
        return np.inf

    # Coefficients in rational approximations
    a = [-3.969683028665376e+01,
          2.209460984245205e+02,
         -2.759285104469687e+02,
          1.383577518672690e+02,
         -3.066479806614716e+01,
          2.506628277459239e+00]

    b = [-5.447609879822406e+01,
          1.615858368580409e+02,
         -1.556989798598866e+02,
          6.680131188771972e+01,
         -1.328068155288572e+01]

    c = [-7.784894002430293e-03,
         -3.223964580411365e-01,
         -2.400758277161838e+00,
         -2.549732539343734e+00,
          4.374664141464968e+00,
          2.938163982698783e+00]

    d = [ 7.784695709041462e-03,
          3.224671290700398e-01,
          2.445134137142996e+00,
          3.754408661907416e+00]

    plow = 0.02425
    phigh = 1 - plow

    if p < plow:
        q = np.sqrt(-2*np.log(p))
        return (((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5]) / \
               ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1)

    if p > phigh:
        q = np.sqrt(-2*np.log(1-p))
        return -(((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5]) / \
                ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1)

    q = p - 0.5
    r = q*q
    return (((((a[0]*r + a[1])*r + a[2])*r + a[3])*r + a[4])*r + a[5]) * q / \
           (((((b[0]*r + b[1])*r + b[2])*r + b[3])*r + b[4])*r + 1)


def logrank_test(df: pd.DataFrame, time_col: str, event_col: str, group_col: str) -> Tuple[float, float, int]:
    """Log-rank test for 2+ groups.

    Returns (chi2, p_value, df).

    Implementation follows the standard Mantel–Cox test with
    variance-covariance matrix across groups at each event time.
    """
    # Clean
    sub = df[[time_col, event_col, group_col]].copy()
    sub = sub.dropna(subset=[time_col, event_col, group_col])
    sub[time_col] = pd.to_numeric(sub[time_col], errors='coerce')
    sub = sub.dropna(subset=[time_col])
    sub[event_col] = _clean_event_vector(sub[event_col])

    groups = list(map(str, sub[group_col].astype(str).unique()))
    k = len(groups)
    if k < 2:
        raise ValueError("Log-rank test needs at least 2 groups.")

    # All unique event times (events only)
    event_times = np.sort(sub.loc[sub[event_col] == 1, time_col].unique())
    if event_times.size == 0:
        raise ValueError("No events found (event==1). Log-rank test undefined.")

    O = np.zeros(k, dtype=float)
    E = np.zeros(k, dtype=float)
    V = np.zeros((k, k), dtype=float)

    for t in event_times:
        # risk set sizes at time t
        n = np.zeros(k, dtype=float)
        d = np.zeros(k, dtype=float)

        at_risk = sub[sub[time_col] >= t]
        at_event = sub[(sub[time_col] == t) & (sub[event_col] == 1)]

        for i, g in enumerate(groups):
            n[i] = (at_risk[group_col].astype(str) == g).sum()
            d[i] = (at_event[group_col].astype(str) == g).sum()

        N = n.sum()
        D = d.sum()
        if N <= 1 or D == 0:
            continue

        # expected events per group
        e = n * (D / N)

        # variance-covariance (hypergeometric)
        # V_ii = e_i*(1 - n_i/N) * (N-D)/(N-1)
        # V_ij = - e_i*(n_j/N) * (N-D)/(N-1)
        factor = (N - D) / (N - 1)
        for i in range(k):
            for j in range(k):
                if i == j:
                    V[i, i] += e[i] * (1.0 - n[i] / N) * factor
                else:
                    V[i, j] += - e[i] * (n[j] / N) * factor

        O += d
        E += e

    # Reduce dimension by removing last group to get full rank
    diff = (O - E)[:k-1]
    V_red = V[:k-1, :k-1]

    # invert with pseudo-inverse for stability
    Vinv = np.linalg.pinv(V_red)
    chi2 = float(diff.T @ Vinv @ diff)
    dfree = k - 1

    # p-value via chi-square survival function; use scipy if available else approximation
    p = _chi2_sf(chi2, dfree)
    return chi2, p, dfree


def _chi2_sf(x: float, k: int) -> float:
    """Survival function for Chi-square(k) at x.

    Tries SciPy if available; else uses regularized gamma approximation.
    """
    try:
        from scipy.stats import chi2
        return float(chi2.sf(x, k))
    except Exception:
        # Use incomplete gamma Q(k/2, x/2)
        return float(_gammaincc(k/2.0, x/2.0))


def _gammaincc(a: float, x: float) -> float:
    """Complemented regularized incomplete gamma Q(a, x).

    Numerical recipes style series/continued fraction.
    """
    if x < 0 or a <= 0:
        return np.nan
    if x == 0:
        return 1.0

    # constants
    ITMAX = 200
    EPS = 3e-14
    FPMIN = 1e-300

    import math

    def gammln(xx):
        return math.lgamma(xx)

    if x < a + 1.0:
        # Use series to compute P, then Q=1-P
        ap = a
        summ = 1.0 / a
        delt = summ
        for _ in range(ITMAX):
            ap += 1.0
            delt *= x / ap
            summ += delt
            if abs(delt) < abs(summ) * EPS:
                break
        P = summ * math.exp(-x + a*math.log(x) - gammln(a))
        return max(0.0, min(1.0, 1.0 - P))

    # Use continued fraction for Q
    b = x + 1.0 - a
    c = 1.0 / FPMIN
    d = 1.0 / b
    h = d
    for i in range(1, ITMAX+1):
        an = -i * (i - a)
        b += 2.0
        d = an * d + b
        if abs(d) < FPMIN:
            d = FPMIN
        c = b + an / c
        if abs(c) < FPMIN:
            c = FPMIN
        d = 1.0 / d
        delta = d * c
        h *= delta
        if abs(delta - 1.0) < EPS:
            break
    Q = math.exp(-x + a*math.log(x) - gammln(a)) * h
    return max(0.0, min(1.0, Q))


def median_survival(km: KMResult) -> float:
    """Return the median survival time (first t where S(t) <= 0.5)."""
    idx = np.where(km.survival <= 0.5)[0]
    if idx.size == 0:
        return float("nan")
    return float(km.time[idx[0]])


# -----------------------------
# GUI
# -----------------------------

class SurvivalAnalysisWindow:
    """Tkinter window for KM plotting and log-rank test."""

    def __init__(self, master: Optional[tk.Tk] = None, title: str = "Survival analysis (Kaplan–Meier)"):
        self.master = master
        self.win = tk.Toplevel(master) if master is not None else tk.Tk()
        self.win.title(title)
        self.win.geometry("1100x720")

        self.df: Optional[pd.DataFrame] = None

        # UI variables
        self.path_var = tk.StringVar(value="")
        self.sheet_var = tk.StringVar(value="")
        self.time_col = tk.StringVar(value="")
        self.event_col = tk.StringVar(value="")
        self.group_col = tk.StringVar(value="")
        self.show_ci = tk.BooleanVar(value=True)
        self.alpha_ci = tk.StringVar(value="0.05")
        self.title_var = tk.StringVar(value="Kaplan–Meier survival")
        self.xlab_var = tk.StringVar(value="Time")
        self.ylab_var = tk.StringVar(value="Survival probability")

        self._build()

    # ---- layout ----
    def _build(self):
        outer = ttk.Frame(self.win, padding=(10, 10))
        outer.pack(fill="both", expand=True)

        # top row: file
        file_row = ttk.LabelFrame(outer, text="Input data", padding=(10, 8))
        file_row.pack(fill="x")

        ttk.Label(file_row, text="File:").grid(row=0, column=0, sticky="w")
        ttk.Entry(file_row, textvariable=self.path_var, width=70).grid(row=0, column=1, sticky="we", padx=(6, 6))
        ttk.Button(file_row, text="Browse…", command=self._browse).grid(row=0, column=2, sticky="e")

        ttk.Label(file_row, text="Excel sheet (optional):").grid(row=1, column=0, sticky="w", pady=(6, 0))
        self.sheet_cb = ttk.Combobox(file_row, textvariable=self.sheet_var, values=[], state="readonly", width=30)
        self.sheet_cb.grid(row=1, column=1, sticky="w", padx=(6, 6), pady=(6, 0))
        ttk.Button(file_row, text="Load", command=self._load).grid(row=1, column=2, sticky="e", pady=(6, 0))

        file_row.grid_columnconfigure(1, weight=1)

        # mapping
        map_row = ttk.LabelFrame(outer, text="Column mapping", padding=(10, 8))
        map_row.pack(fill="x", pady=(10, 0))

        ttk.Label(map_row, text="Time column:").grid(row=0, column=0, sticky="w")
        self.time_cb = ttk.Combobox(map_row, textvariable=self.time_col, values=[], state="readonly", width=30)
        self.time_cb.grid(row=0, column=1, sticky="w", padx=(6, 12))

        ttk.Label(map_row, text="Event column (1=event, 0=censored):").grid(row=0, column=2, sticky="w")
        self.event_cb = ttk.Combobox(map_row, textvariable=self.event_col, values=[], state="readonly", width=30)
        self.event_cb.grid(row=0, column=3, sticky="w", padx=(6, 0))

        ttk.Label(map_row, text="Group column (optional):").grid(row=1, column=0, sticky="w", pady=(6, 0))
        self.group_cb = ttk.Combobox(map_row, textvariable=self.group_col, values=[""], state="readonly", width=30)
        self.group_cb.grid(row=1, column=1, sticky="w", padx=(6, 12), pady=(6, 0))

        ttk.Checkbutton(map_row, text="Show 95% CI (log-log)", variable=self.show_ci).grid(row=1, column=2, sticky="w", pady=(6, 0))
        ttk.Label(map_row, text="alpha:").grid(row=1, column=3, sticky="w", padx=(0, 0), pady=(6, 0))
        ttk.Entry(map_row, textvariable=self.alpha_ci, width=8).grid(row=1, column=3, sticky="e", padx=(0, 0), pady=(6, 0))

        # labels
        lbl_row = ttk.LabelFrame(outer, text="Plot labels", padding=(10, 8))
        lbl_row.pack(fill="x", pady=(10, 0))

        ttk.Label(lbl_row, text="Title:").grid(row=0, column=0, sticky="w")
        ttk.Entry(lbl_row, textvariable=self.title_var, width=40).grid(row=0, column=1, sticky="w", padx=(6, 12))
        ttk.Label(lbl_row, text="X label:").grid(row=0, column=2, sticky="w")
        ttk.Entry(lbl_row, textvariable=self.xlab_var, width=20).grid(row=0, column=3, sticky="w", padx=(6, 12))
        ttk.Label(lbl_row, text="Y label:").grid(row=0, column=4, sticky="w")
        ttk.Entry(lbl_row, textvariable=self.ylab_var, width=22).grid(row=0, column=5, sticky="w", padx=(6, 0))

        # action buttons
        btn_row = ttk.Frame(outer)
        btn_row.pack(fill="x", pady=(12, 0))
        ttk.Button(btn_row, text="Plot KM", command=self._plot).pack(side="left")
        ttk.Button(btn_row, text="Log-rank test", command=self._logrank).pack(side="left", padx=(8, 0))
        ttk.Button(btn_row, text="KM + log-rank", command=self._plot_and_logrank).pack(side="left", padx=(8, 0))
        ttk.Button(btn_row, text="Close", command=self.win.destroy).pack(side="right")

        # results box
        res_frame = ttk.LabelFrame(outer, text="Results", padding=(10, 8))
        res_frame.pack(fill="both", expand=True, pady=(10, 0))
        self.text = tk.Text(res_frame, height=16, wrap="word")
        self.text.pack(fill="both", expand=True)

        self._log("Load a survival dataset with columns like: time, event, group (optional).\n")

    # ---- helpers ----
    def _log(self, msg: str):
        self.text.insert("end", msg)
        self.text.see("end")

    def _browse(self):
        path = filedialog.askopenfilename(
            title="Select survival data file",
            filetypes=[
                ("CSV or Excel", "*.csv *.xlsx *.xls *.xlsm *.xltx *.xltm"),
                ("CSV", "*.csv"),
                ("Excel", "*.xlsx *.xls *.xlsm"),
                ("All files", "*.*"),
            ],
        )
        if not path:
            return
        self.path_var.set(path)

        # If Excel, populate sheet names
        ext = os.path.splitext(path)[1].lower()
        if ext in {".xlsx", ".xlsm", ".xltx", ".xltm", ".xls"}:
            try:
                xls = pd.ExcelFile(path)
                sheets = list(xls.sheet_names)
                self.sheet_cb.configure(values=[""] + sheets)
                if sheets:
                    self.sheet_var.set(sheets[0])
            except Exception as e:
                self.sheet_cb.configure(values=[""])
                self.sheet_var.set("")
                self._log(f"(Excel) Could not read sheet names: {e}\n")
        else:
            self.sheet_cb.configure(values=[""])
            self.sheet_var.set("")

    def _load(self):
        path = self.path_var.get().strip()
        if not path:
            messagebox.showerror("Load", "Please choose a file first.")
            return
        if not os.path.exists(path):
            messagebox.showerror("Load", f"File not found: {path}")
            return

        ext = os.path.splitext(path)[1].lower()
        sheet = self.sheet_var.get().strip() or 0

        try:
            if ext in {".xlsx", ".xlsm", ".xltx", ".xltm", ".xls"}:
                self.df = pd.read_excel(path, sheet_name=sheet)
            else:
                # try common separators; pandas can infer
                self.df = pd.read_csv(path)
        except Exception as e:
            messagebox.showerror("Load", f"Failed to read file:\n{type(e).__name__}: {e}")
            return

        if self.df is None or self.df.empty:
            messagebox.showerror("Load", "File loaded but contains no rows.")
            return

        cols = list(map(str, self.df.columns))
        self.time_cb.configure(values=cols)
        self.event_cb.configure(values=cols)
        self.group_cb.configure(values=[""] + cols)

        # Best-effort defaults
        def _guess(names: List[str], targets: List[str]) -> str:
            low = [n.lower() for n in names]
            for t in targets:
                if t in low:
                    return names[low.index(t)]
            return ""

        if not self.time_col.get():
            self.time_col.set(_guess(cols, ["time", "followup", "days", "months", "weeks"]) or cols[0])
        if not self.event_col.get():
            self.event_col.set(_guess(cols, ["event", "status", "death", "progression"]) or (cols[1] if len(cols) > 1 else cols[0]))
        if not self.group_col.get():
            self.group_col.set(_guess(cols, ["group", "arm", "treatment", "cohort"]) )

        self._log(f"Loaded: {os.path.basename(path)}  (rows={len(self.df)}, cols={len(cols)})\n")

    def _get_ready_df(self) -> pd.DataFrame:
        if self.df is None:
            raise ValueError("No data loaded.")
        tc = self.time_col.get().strip()
        ec = self.event_col.get().strip()
        if not tc or not ec:
            raise ValueError("Select both time and event columns.")
        if tc not in self.df.columns or ec not in self.df.columns:
            raise ValueError("Selected columns not found in the dataset.")

        sub = self.df.copy()
        sub[tc] = pd.to_numeric(sub[tc], errors='coerce')
        sub = sub.dropna(subset=[tc])
        sub[ec] = _clean_event_vector(sub[ec])

        gc = self.group_col.get().strip()
        if gc and gc in sub.columns:
            sub[gc] = sub[gc].astype(str)
        else:
            gc = ""
        self._time = tc
        self._event = ec
        self._group = gc
        return sub

    def _plot(self):
        try:
            sub = self._get_ready_df()
        except Exception as e:
            messagebox.showerror("Plot", str(e))
            return

        alpha = self._parse_alpha()
        show_ci = self.show_ci.get()

        plt.rcParams.update({"figure.dpi": 160, "axes.spines.top": False, "axes.spines.right": False})
        fig, ax = plt.subplots(figsize=(8.5, 5.4))

        if self._group:
            groups = list(map(str, sub[self._group].unique()))
        else:
            groups = ["All"]
            sub = sub.assign(_ALL_="All")
            self._group = "_ALL_"

        colors = plt.get_cmap("tab10")

        self._log("\n=== Kaplan–Meier ===\n")
        self._log(f"time={self._time}, event={self._event}, group={self._group if self._group!='_ALL_' else '(none)'}\n")

        for i, g in enumerate(groups):
            dfg = sub[sub[self._group] == g]
            km = kaplan_meier(dfg[self._time].to_numpy(), dfg[self._event].to_numpy())
            col = colors(i % 10)

            ax.step(km.time, km.survival, where="post", lw=2.2, color=col, label=f"{g} (n={len(dfg)})")

            med = median_survival(km)
            self._log(f"{g}: n={len(dfg)}, events={int(dfg[self._event].sum())}, median={med if np.isfinite(med) else 'NA'}\n")

            if show_ci:
                lo, hi = km_loglog_ci(km, alpha=alpha)
                ax.fill_between(km.time, lo, hi, step="post", color=col, alpha=0.15, linewidth=0)

        ax.set_title(self.title_var.get().strip() or "Kaplan–Meier survival")
        ax.set_xlabel(self.xlab_var.get().strip() or self._time)
        ax.set_ylabel(self.ylab_var.get().strip() or "Survival probability")
        ax.set_ylim(-0.02, 1.02)
        ax.grid(True, alpha=0.25)
        ax.legend(loc="best", fontsize=9)
        plt.tight_layout()
        plt.show(block=True)

    def _parse_alpha(self) -> float:
        try:
            a = float(self.alpha_ci.get().strip())
            if not (0.0 < a < 1.0):
                raise ValueError
            return a
        except Exception:
            return 0.05

    def _logrank(self):
        try:
            sub = self._get_ready_df()
        except Exception as e:
            messagebox.showerror("Log-rank", str(e))
            return

        if not self._group:
            messagebox.showwarning("Log-rank", "Group column is empty. Log-rank requires ≥2 groups.")
            return

        try:
            chi2, p, dfree = logrank_test(sub, self._time, self._event, self._group)
            self._log("\n=== Log-rank test (Mantel–Cox) ===\n")
            self._log(f"Groups: {sorted(sub[self._group].astype(str).unique())}\n")
            self._log(f"Chi-square({dfree}) = {chi2:.4f}\n")
            self._log(f"p = {p:.4e}\n")
        except Exception as e:
            messagebox.showerror("Log-rank", str(e))

    def _plot_and_logrank(self):
        self._plot()
        self._logrank()


# Convenience launcher (optional)

def launch_survival_tool():
    SurvivalAnalysisWindow(master=None)


if __name__ == "__main__":
    launch_survival_tool()
